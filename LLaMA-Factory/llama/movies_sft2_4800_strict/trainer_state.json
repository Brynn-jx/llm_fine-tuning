{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 200.0,
  "global_step": 1725,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.017391304347826087,
      "grad_norm": 2.3734519481658936,
      "learning_rate": 4.000000000000001e-06,
      "loss": 2.1268,
      "step": 10
    },
    {
      "epoch": 0.034782608695652174,
      "grad_norm": 3.0957276821136475,
      "learning_rate": 8.500000000000002e-06,
      "loss": 2.1612,
      "step": 20
    },
    {
      "epoch": 0.05217391304347826,
      "grad_norm": 2.354733467102051,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 1.8793,
      "step": 30
    },
    {
      "epoch": 0.06956521739130435,
      "grad_norm": 2.864764451980591,
      "learning_rate": 1.85e-05,
      "loss": 1.7846,
      "step": 40
    },
    {
      "epoch": 0.08695652173913043,
      "grad_norm": 2.2347185611724854,
      "learning_rate": 2.35e-05,
      "loss": 1.4548,
      "step": 50
    },
    {
      "epoch": 0.10434782608695652,
      "grad_norm": 2.121521472930908,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 1.098,
      "step": 60
    },
    {
      "epoch": 0.12173913043478261,
      "grad_norm": 1.8027629852294922,
      "learning_rate": 3.35e-05,
      "loss": 0.8733,
      "step": 70
    },
    {
      "epoch": 0.1391304347826087,
      "grad_norm": 1.8203221559524536,
      "learning_rate": 3.85e-05,
      "loss": 0.8241,
      "step": 80
    },
    {
      "epoch": 0.1565217391304348,
      "grad_norm": 2.2270913124084473,
      "learning_rate": 4.35e-05,
      "loss": 0.6496,
      "step": 90
    },
    {
      "epoch": 0.17391304347826086,
      "grad_norm": 1.8486484289169312,
      "learning_rate": 4.85e-05,
      "loss": 0.5406,
      "step": 100
    },
    {
      "epoch": 0.19130434782608696,
      "grad_norm": 1.6372880935668945,
      "learning_rate": 4.999771075391766e-05,
      "loss": 0.4885,
      "step": 110
    },
    {
      "epoch": 0.20869565217391303,
      "grad_norm": 1.949363112449646,
      "learning_rate": 4.998649912931086e-05,
      "loss": 0.3529,
      "step": 120
    },
    {
      "epoch": 0.22608695652173913,
      "grad_norm": 1.1588584184646606,
      "learning_rate": 4.996594883749894e-05,
      "loss": 0.3898,
      "step": 130
    },
    {
      "epoch": 0.24347826086956523,
      "grad_norm": 1.5193570852279663,
      "learning_rate": 4.993606755912317e-05,
      "loss": 0.3852,
      "step": 140
    },
    {
      "epoch": 0.2608695652173913,
      "grad_norm": 1.2164146900177002,
      "learning_rate": 4.989686646226728e-05,
      "loss": 0.2627,
      "step": 150
    },
    {
      "epoch": 0.2782608695652174,
      "grad_norm": 0.8023686408996582,
      "learning_rate": 4.984836019828342e-05,
      "loss": 0.2309,
      "step": 160
    },
    {
      "epoch": 0.2956521739130435,
      "grad_norm": 0.9954809546470642,
      "learning_rate": 4.9790566896316215e-05,
      "loss": 0.2266,
      "step": 170
    },
    {
      "epoch": 0.3130434782608696,
      "grad_norm": 1.0201793909072876,
      "learning_rate": 4.972350815652707e-05,
      "loss": 0.1964,
      "step": 180
    },
    {
      "epoch": 0.33043478260869563,
      "grad_norm": 1.0645273923873901,
      "learning_rate": 4.964720904202108e-05,
      "loss": 0.1941,
      "step": 190
    },
    {
      "epoch": 0.34782608695652173,
      "grad_norm": 2.226503849029541,
      "learning_rate": 4.95616980694798e-05,
      "loss": 0.2052,
      "step": 200
    },
    {
      "epoch": 0.3652173913043478,
      "grad_norm": 1.1100988388061523,
      "learning_rate": 4.946700719850312e-05,
      "loss": 0.1496,
      "step": 210
    },
    {
      "epoch": 0.3826086956521739,
      "grad_norm": 1.822218894958496,
      "learning_rate": 4.9363171819664434e-05,
      "loss": 0.1479,
      "step": 220
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.135585904121399,
      "learning_rate": 4.9250230741283466e-05,
      "loss": 0.1434,
      "step": 230
    },
    {
      "epoch": 0.41739130434782606,
      "grad_norm": 2.7756640911102295,
      "learning_rate": 4.9128226174921736e-05,
      "loss": 0.1343,
      "step": 240
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 0.8688363432884216,
      "learning_rate": 4.899720371960601e-05,
      "loss": 0.148,
      "step": 250
    },
    {
      "epoch": 0.45217391304347826,
      "grad_norm": 1.084541916847229,
      "learning_rate": 4.8857212344785754e-05,
      "loss": 0.1373,
      "step": 260
    },
    {
      "epoch": 0.46956521739130436,
      "grad_norm": 0.7882939577102661,
      "learning_rate": 4.870830437203088e-05,
      "loss": 0.1089,
      "step": 270
    },
    {
      "epoch": 0.48695652173913045,
      "grad_norm": 0.9703043103218079,
      "learning_rate": 4.855053545547664e-05,
      "loss": 0.1065,
      "step": 280
    },
    {
      "epoch": 0.5043478260869565,
      "grad_norm": 0.9051695466041565,
      "learning_rate": 4.8383964561022946e-05,
      "loss": 0.0936,
      "step": 290
    },
    {
      "epoch": 0.5217391304347826,
      "grad_norm": 0.6563939452171326,
      "learning_rate": 4.820865394429597e-05,
      "loss": 0.0783,
      "step": 300
    },
    {
      "epoch": 0.5391304347826087,
      "grad_norm": 2.0840580463409424,
      "learning_rate": 4.802466912738022e-05,
      "loss": 0.0794,
      "step": 310
    },
    {
      "epoch": 0.5565217391304348,
      "grad_norm": 1.070469856262207,
      "learning_rate": 4.783207887432971e-05,
      "loss": 0.0779,
      "step": 320
    },
    {
      "epoch": 0.5739130434782609,
      "grad_norm": 0.9281961917877197,
      "learning_rate": 4.7630955165467536e-05,
      "loss": 0.0727,
      "step": 330
    },
    {
      "epoch": 0.591304347826087,
      "grad_norm": 0.7443646788597107,
      "learning_rate": 4.742137317048331e-05,
      "loss": 0.0821,
      "step": 340
    },
    {
      "epoch": 0.6086956521739131,
      "grad_norm": 0.6137827634811401,
      "learning_rate": 4.720341122033862e-05,
      "loss": 0.0665,
      "step": 350
    },
    {
      "epoch": 0.6260869565217392,
      "grad_norm": 0.5794081687927246,
      "learning_rate": 4.697715077799091e-05,
      "loss": 0.066,
      "step": 360
    },
    {
      "epoch": 0.6434782608695652,
      "grad_norm": 0.9558050632476807,
      "learning_rate": 4.6742676407946886e-05,
      "loss": 0.0555,
      "step": 370
    },
    {
      "epoch": 0.6608695652173913,
      "grad_norm": 0.67464280128479,
      "learning_rate": 4.6500075744656605e-05,
      "loss": 0.0514,
      "step": 380
    },
    {
      "epoch": 0.6782608695652174,
      "grad_norm": 0.5215206742286682,
      "learning_rate": 4.624943945976023e-05,
      "loss": 0.0472,
      "step": 390
    },
    {
      "epoch": 0.6956521739130435,
      "grad_norm": 0.7594699859619141,
      "learning_rate": 4.599086122819966e-05,
      "loss": 0.0621,
      "step": 400
    },
    {
      "epoch": 0.7130434782608696,
      "grad_norm": 0.8027986288070679,
      "learning_rate": 4.572443769320766e-05,
      "loss": 0.0466,
      "step": 410
    },
    {
      "epoch": 0.7304347826086957,
      "grad_norm": 0.8108358383178711,
      "learning_rate": 4.545026843018755e-05,
      "loss": 0.0526,
      "step": 420
    },
    {
      "epoch": 0.7478260869565218,
      "grad_norm": 0.5579898953437805,
      "learning_rate": 4.516845590949711e-05,
      "loss": 0.0451,
      "step": 430
    },
    {
      "epoch": 0.7652173913043478,
      "grad_norm": 0.4454181492328644,
      "learning_rate": 4.4879105458150406e-05,
      "loss": 0.0409,
      "step": 440
    },
    {
      "epoch": 0.782608695652174,
      "grad_norm": 0.3849496841430664,
      "learning_rate": 4.458232522045194e-05,
      "loss": 0.0394,
      "step": 450
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.44648686051368713,
      "learning_rate": 4.427822611757795e-05,
      "loss": 0.0426,
      "step": 460
    },
    {
      "epoch": 0.8173913043478261,
      "grad_norm": 0.4083448052406311,
      "learning_rate": 4.3966921806119696e-05,
      "loss": 0.037,
      "step": 470
    },
    {
      "epoch": 0.8347826086956521,
      "grad_norm": 0.7178537249565125,
      "learning_rate": 4.3648528635604556e-05,
      "loss": 0.037,
      "step": 480
    },
    {
      "epoch": 0.8521739130434782,
      "grad_norm": 0.3605990409851074,
      "learning_rate": 4.332316560501051e-05,
      "loss": 0.0375,
      "step": 490
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 1.120618224143982,
      "learning_rate": 4.2990954318290475e-05,
      "loss": 0.0387,
      "step": 500
    },
    {
      "epoch": 0.8869565217391304,
      "grad_norm": 0.48268014192581177,
      "learning_rate": 4.2652018938923e-05,
      "loss": 0.0411,
      "step": 510
    },
    {
      "epoch": 0.9043478260869565,
      "grad_norm": 0.44917726516723633,
      "learning_rate": 4.230648614350632e-05,
      "loss": 0.0389,
      "step": 520
    },
    {
      "epoch": 0.9217391304347826,
      "grad_norm": 0.6522257328033447,
      "learning_rate": 4.195448507441322e-05,
      "loss": 0.0348,
      "step": 530
    },
    {
      "epoch": 0.9391304347826087,
      "grad_norm": 0.3593685030937195,
      "learning_rate": 4.159614729152421e-05,
      "loss": 0.0312,
      "step": 540
    },
    {
      "epoch": 0.9565217391304348,
      "grad_norm": 0.4638969302177429,
      "learning_rate": 4.123160672305727e-05,
      "loss": 0.0355,
      "step": 550
    },
    {
      "epoch": 0.9739130434782609,
      "grad_norm": 0.896691083908081,
      "learning_rate": 4.08609996155123e-05,
      "loss": 0.0364,
      "step": 560
    },
    {
      "epoch": 0.991304347826087,
      "grad_norm": 0.40733855962753296,
      "learning_rate": 4.048446448274926e-05,
      "loss": 0.0341,
      "step": 570
    },
    {
      "epoch": 1.008695652173913,
      "grad_norm": 0.4563671052455902,
      "learning_rate": 4.010214205421881e-05,
      "loss": 0.0349,
      "step": 580
    },
    {
      "epoch": 1.0260869565217392,
      "grad_norm": 0.45340800285339355,
      "learning_rate": 3.971417522236482e-05,
      "loss": 0.0337,
      "step": 590
    },
    {
      "epoch": 1.0434782608695652,
      "grad_norm": 0.5537703633308411,
      "learning_rate": 3.932070898921865e-05,
      "loss": 0.0304,
      "step": 600
    },
    {
      "epoch": 1.0608695652173914,
      "grad_norm": 0.3820632994174957,
      "learning_rate": 3.8921890412204705e-05,
      "loss": 0.032,
      "step": 610
    },
    {
      "epoch": 1.0782608695652174,
      "grad_norm": 0.38547059893608093,
      "learning_rate": 3.851786854917807e-05,
      "loss": 0.032,
      "step": 620
    },
    {
      "epoch": 1.0956521739130434,
      "grad_norm": 0.37178876996040344,
      "learning_rate": 3.8108794402714293e-05,
      "loss": 0.0294,
      "step": 630
    },
    {
      "epoch": 1.1130434782608696,
      "grad_norm": 0.38948410749435425,
      "learning_rate": 3.76948208636724e-05,
      "loss": 0.0301,
      "step": 640
    },
    {
      "epoch": 1.1304347826086956,
      "grad_norm": 0.6462221741676331,
      "learning_rate": 3.727610265405218e-05,
      "loss": 0.0325,
      "step": 650
    },
    {
      "epoch": 1.1478260869565218,
      "grad_norm": 0.4276449382305145,
      "learning_rate": 3.6852796269167036e-05,
      "loss": 0.0322,
      "step": 660
    },
    {
      "epoch": 1.1652173913043478,
      "grad_norm": 0.423801451921463,
      "learning_rate": 3.642505991915412e-05,
      "loss": 0.0285,
      "step": 670
    },
    {
      "epoch": 1.182608695652174,
      "grad_norm": 0.6052711009979248,
      "learning_rate": 3.599305346984355e-05,
      "loss": 0.0353,
      "step": 680
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.28529566526412964,
      "learning_rate": 3.55569383830087e-05,
      "loss": 0.0287,
      "step": 690
    },
    {
      "epoch": 1.2173913043478262,
      "grad_norm": 0.34134915471076965,
      "learning_rate": 3.5116877656020194e-05,
      "loss": 0.0318,
      "step": 700
    },
    {
      "epoch": 1.2347826086956522,
      "grad_norm": 0.4025842845439911,
      "learning_rate": 3.467303576092584e-05,
      "loss": 0.0326,
      "step": 710
    },
    {
      "epoch": 1.2521739130434781,
      "grad_norm": 0.37723204493522644,
      "learning_rate": 3.4225578582979465e-05,
      "loss": 0.0293,
      "step": 720
    },
    {
      "epoch": 1.2695652173913043,
      "grad_norm": 0.40709200501441956,
      "learning_rate": 3.377467335864151e-05,
      "loss": 0.032,
      "step": 730
    },
    {
      "epoch": 1.2869565217391306,
      "grad_norm": 0.3727037012577057,
      "learning_rate": 3.332048861307467e-05,
      "loss": 0.0314,
      "step": 740
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": 0.3955838978290558,
      "learning_rate": 3.286319409715788e-05,
      "loss": 0.0295,
      "step": 750
    },
    {
      "epoch": 1.3217391304347825,
      "grad_norm": 0.2384856641292572,
      "learning_rate": 3.240296072404215e-05,
      "loss": 0.0267,
      "step": 760
    },
    {
      "epoch": 1.3391304347826087,
      "grad_norm": 0.3865812122821808,
      "learning_rate": 3.1939960505272026e-05,
      "loss": 0.0267,
      "step": 770
    },
    {
      "epoch": 1.3565217391304347,
      "grad_norm": 0.4124967157840729,
      "learning_rate": 3.147436648649655e-05,
      "loss": 0.0263,
      "step": 780
    },
    {
      "epoch": 1.373913043478261,
      "grad_norm": 0.3336437940597534,
      "learning_rate": 3.100635268279369e-05,
      "loss": 0.026,
      "step": 790
    },
    {
      "epoch": 1.391304347826087,
      "grad_norm": 0.29117152094841003,
      "learning_rate": 3.053609401363245e-05,
      "loss": 0.0288,
      "step": 800
    },
    {
      "epoch": 1.4086956521739131,
      "grad_norm": 0.33033451437950134,
      "learning_rate": 3.0063766237496992e-05,
      "loss": 0.0269,
      "step": 810
    },
    {
      "epoch": 1.4260869565217391,
      "grad_norm": 0.40612515807151794,
      "learning_rate": 2.958954588619719e-05,
      "loss": 0.0301,
      "step": 820
    },
    {
      "epoch": 1.4434782608695653,
      "grad_norm": 0.3627181351184845,
      "learning_rate": 2.911361019889004e-05,
      "loss": 0.0273,
      "step": 830
    },
    {
      "epoch": 1.4608695652173913,
      "grad_norm": 0.44979745149612427,
      "learning_rate": 2.8636137055836883e-05,
      "loss": 0.0264,
      "step": 840
    },
    {
      "epoch": 1.4782608695652173,
      "grad_norm": 0.3611984848976135,
      "learning_rate": 2.8157304911920868e-05,
      "loss": 0.0284,
      "step": 850
    },
    {
      "epoch": 1.4956521739130435,
      "grad_norm": 0.39915403723716736,
      "learning_rate": 2.7677292729949695e-05,
      "loss": 0.0273,
      "step": 860
    },
    {
      "epoch": 1.5130434782608697,
      "grad_norm": 0.3420957922935486,
      "learning_rate": 2.7196279913768584e-05,
      "loss": 0.0274,
      "step": 870
    },
    {
      "epoch": 1.5304347826086957,
      "grad_norm": 0.3275536298751831,
      "learning_rate": 2.671444624120828e-05,
      "loss": 0.0273,
      "step": 880
    },
    {
      "epoch": 1.5478260869565217,
      "grad_norm": 0.38700953125953674,
      "learning_rate": 2.623197179689339e-05,
      "loss": 0.0268,
      "step": 890
    },
    {
      "epoch": 1.5652173913043477,
      "grad_norm": 0.3532108962535858,
      "learning_rate": 2.5749036904936064e-05,
      "loss": 0.0319,
      "step": 900
    },
    {
      "epoch": 1.5826086956521739,
      "grad_norm": 0.20891320705413818,
      "learning_rate": 2.526582206154002e-05,
      "loss": 0.0322,
      "step": 910
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.392273485660553,
      "learning_rate": 2.4782507867540453e-05,
      "loss": 0.0281,
      "step": 920
    },
    {
      "epoch": 1.617391304347826,
      "grad_norm": 0.34535232186317444,
      "learning_rate": 2.4299274960904684e-05,
      "loss": 0.0277,
      "step": 930
    },
    {
      "epoch": 1.634782608695652,
      "grad_norm": 0.3823630213737488,
      "learning_rate": 2.3816303949219005e-05,
      "loss": 0.0273,
      "step": 940
    },
    {
      "epoch": 1.6521739130434783,
      "grad_norm": 0.2915346324443817,
      "learning_rate": 2.3333775342186852e-05,
      "loss": 0.0281,
      "step": 950
    },
    {
      "epoch": 1.6695652173913045,
      "grad_norm": 0.38313692808151245,
      "learning_rate": 2.2851869484163595e-05,
      "loss": 0.0291,
      "step": 960
    },
    {
      "epoch": 1.6869565217391305,
      "grad_norm": 0.3772839307785034,
      "learning_rate": 2.237076648675304e-05,
      "loss": 0.0321,
      "step": 970
    },
    {
      "epoch": 1.7043478260869565,
      "grad_norm": 0.2814020812511444,
      "learning_rate": 2.1890646161491062e-05,
      "loss": 0.0315,
      "step": 980
    },
    {
      "epoch": 1.7217391304347827,
      "grad_norm": 0.39700835943222046,
      "learning_rate": 2.1411687952641254e-05,
      "loss": 0.0274,
      "step": 990
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 0.2959331274032593,
      "learning_rate": 2.0934070870127912e-05,
      "loss": 0.0265,
      "step": 1000
    },
    {
      "epoch": 1.7565217391304349,
      "grad_norm": 0.6128156185150146,
      "learning_rate": 2.0457973422631344e-05,
      "loss": 0.0312,
      "step": 1010
    },
    {
      "epoch": 1.7739130434782608,
      "grad_norm": 0.3731490671634674,
      "learning_rate": 1.9983573550870505e-05,
      "loss": 0.0266,
      "step": 1020
    },
    {
      "epoch": 1.7913043478260868,
      "grad_norm": 0.31206321716308594,
      "learning_rate": 1.951104856109793e-05,
      "loss": 0.0255,
      "step": 1030
    },
    {
      "epoch": 1.808695652173913,
      "grad_norm": 0.2285241186618805,
      "learning_rate": 1.904057505883177e-05,
      "loss": 0.0298,
      "step": 1040
    },
    {
      "epoch": 1.8260869565217392,
      "grad_norm": 0.2528513967990875,
      "learning_rate": 1.857232888284976e-05,
      "loss": 0.0273,
      "step": 1050
    },
    {
      "epoch": 1.8434782608695652,
      "grad_norm": 0.41192975640296936,
      "learning_rate": 1.8106485039469705e-05,
      "loss": 0.0284,
      "step": 1060
    },
    {
      "epoch": 1.8608695652173912,
      "grad_norm": 0.23708468675613403,
      "learning_rate": 1.7643217637141138e-05,
      "loss": 0.0261,
      "step": 1070
    },
    {
      "epoch": 1.8782608695652174,
      "grad_norm": 0.25307130813598633,
      "learning_rate": 1.718269982137256e-05,
      "loss": 0.0275,
      "step": 1080
    },
    {
      "epoch": 1.8956521739130436,
      "grad_norm": 0.35023507475852966,
      "learning_rate": 1.6725103710018546e-05,
      "loss": 0.0265,
      "step": 1090
    },
    {
      "epoch": 1.9130434782608696,
      "grad_norm": 0.4011170566082001,
      "learning_rate": 1.6270600328950964e-05,
      "loss": 0.0278,
      "step": 1100
    },
    {
      "epoch": 1.9304347826086956,
      "grad_norm": 0.44467097520828247,
      "learning_rate": 1.581935954813828e-05,
      "loss": 0.0315,
      "step": 1110
    },
    {
      "epoch": 1.9478260869565216,
      "grad_norm": 0.31494832038879395,
      "learning_rate": 1.5371550018156938e-05,
      "loss": 0.0279,
      "step": 1120
    },
    {
      "epoch": 1.9652173913043478,
      "grad_norm": 0.3988116383552551,
      "learning_rate": 1.4927339107158437e-05,
      "loss": 0.0287,
      "step": 1130
    },
    {
      "epoch": 1.982608695652174,
      "grad_norm": 0.4051710367202759,
      "learning_rate": 1.4486892838315735e-05,
      "loss": 0.029,
      "step": 1140
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.27605247497558594,
      "learning_rate": 1.4050375827772358e-05,
      "loss": 0.0249,
      "step": 1150
    },
    {
      "epoch": 2.017391304347826,
      "grad_norm": 0.2636840045452118,
      "learning_rate": 1.361795122311731e-05,
      "loss": 0.0246,
      "step": 1160
    },
    {
      "epoch": 2.034782608695652,
      "grad_norm": 0.38080060482025146,
      "learning_rate": 1.3189780642408927e-05,
      "loss": 0.0249,
      "step": 1170
    },
    {
      "epoch": 2.0521739130434784,
      "grad_norm": 0.3148902356624603,
      "learning_rate": 1.2766024113770386e-05,
      "loss": 0.0255,
      "step": 1180
    },
    {
      "epoch": 2.0695652173913044,
      "grad_norm": 0.340638130903244,
      "learning_rate": 1.2346840015579422e-05,
      "loss": 0.0262,
      "step": 1190
    },
    {
      "epoch": 2.0869565217391304,
      "grad_norm": 0.34292250871658325,
      "learning_rate": 1.1932385017274592e-05,
      "loss": 0.0267,
      "step": 1200
    },
    {
      "epoch": 2.1043478260869564,
      "grad_norm": 0.3013627529144287,
      "learning_rate": 1.1522814020800386e-05,
      "loss": 0.0263,
      "step": 1210
    },
    {
      "epoch": 2.121739130434783,
      "grad_norm": 0.32049503922462463,
      "learning_rate": 1.1118280102712782e-05,
      "loss": 0.0245,
      "step": 1220
    },
    {
      "epoch": 2.139130434782609,
      "grad_norm": 0.295567125082016,
      "learning_rate": 1.0718934456967144e-05,
      "loss": 0.024,
      "step": 1230
    },
    {
      "epoch": 2.1565217391304348,
      "grad_norm": 0.3376712501049042,
      "learning_rate": 1.0324926338409713e-05,
      "loss": 0.0261,
      "step": 1240
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 0.3016381859779358,
      "learning_rate": 9.936403006993814e-06,
      "loss": 0.0252,
      "step": 1250
    },
    {
      "epoch": 2.1913043478260867,
      "grad_norm": 0.3731699287891388,
      "learning_rate": 9.553509672741645e-06,
      "loss": 0.027,
      "step": 1260
    },
    {
      "epoch": 2.208695652173913,
      "grad_norm": 0.34092122316360474,
      "learning_rate": 9.176389441472275e-06,
      "loss": 0.0241,
      "step": 1270
    },
    {
      "epoch": 2.226086956521739,
      "grad_norm": 0.3945731818675995,
      "learning_rate": 8.805183261316061e-06,
      "loss": 0.0245,
      "step": 1280
    },
    {
      "epoch": 2.243478260869565,
      "grad_norm": 0.470788836479187,
      "learning_rate": 8.440029870035448e-06,
      "loss": 0.0282,
      "step": 1290
    },
    {
      "epoch": 2.260869565217391,
      "grad_norm": 0.2682797908782959,
      "learning_rate": 8.081065743172e-06,
      "loss": 0.0293,
      "step": 1300
    },
    {
      "epoch": 2.2782608695652176,
      "grad_norm": 0.3069661855697632,
      "learning_rate": 7.728425043038807e-06,
      "loss": 0.0244,
      "step": 1310
    },
    {
      "epoch": 2.2956521739130435,
      "grad_norm": 0.3598026633262634,
      "learning_rate": 7.382239568577531e-06,
      "loss": 0.0266,
      "step": 1320
    },
    {
      "epoch": 2.3130434782608695,
      "grad_norm": 0.36735546588897705,
      "learning_rate": 7.042638706098795e-06,
      "loss": 0.0245,
      "step": 1330
    },
    {
      "epoch": 2.3304347826086955,
      "grad_norm": 0.35501113533973694,
      "learning_rate": 6.709749380924185e-06,
      "loss": 0.0265,
      "step": 1340
    },
    {
      "epoch": 2.3478260869565215,
      "grad_norm": 0.26112696528434753,
      "learning_rate": 6.383696009948109e-06,
      "loss": 0.0245,
      "step": 1350
    },
    {
      "epoch": 2.365217391304348,
      "grad_norm": 0.3659875988960266,
      "learning_rate": 6.06460045513717e-06,
      "loss": 0.0253,
      "step": 1360
    },
    {
      "epoch": 2.382608695652174,
      "grad_norm": 0.31938061118125916,
      "learning_rate": 5.752581977984464e-06,
      "loss": 0.0239,
      "step": 1370
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.3052126467227936,
      "learning_rate": 5.447757194935718e-06,
      "loss": 0.0282,
      "step": 1380
    },
    {
      "epoch": 2.417391304347826,
      "grad_norm": 0.4164690673351288,
      "learning_rate": 5.150240033804116e-06,
      "loss": 0.0254,
      "step": 1390
    },
    {
      "epoch": 2.4347826086956523,
      "grad_norm": 0.4147941768169403,
      "learning_rate": 4.860141691189926e-06,
      "loss": 0.0245,
      "step": 1400
    },
    {
      "epoch": 2.4521739130434783,
      "grad_norm": 0.30685389041900635,
      "learning_rate": 4.577570590920921e-06,
      "loss": 0.0258,
      "step": 1410
    },
    {
      "epoch": 2.4695652173913043,
      "grad_norm": 0.4507327079772949,
      "learning_rate": 4.30263234352915e-06,
      "loss": 0.0238,
      "step": 1420
    },
    {
      "epoch": 2.4869565217391303,
      "grad_norm": 0.3859477937221527,
      "learning_rate": 4.035429706779165e-06,
      "loss": 0.023,
      "step": 1430
    },
    {
      "epoch": 2.5043478260869563,
      "grad_norm": 0.3641558885574341,
      "learning_rate": 3.7760625472624463e-06,
      "loss": 0.0267,
      "step": 1440
    },
    {
      "epoch": 2.5217391304347827,
      "grad_norm": 0.3741578459739685,
      "learning_rate": 3.5246278030723974e-06,
      "loss": 0.0234,
      "step": 1450
    },
    {
      "epoch": 2.5391304347826087,
      "grad_norm": 0.31339597702026367,
      "learning_rate": 3.2812194475738995e-06,
      "loss": 0.0255,
      "step": 1460
    },
    {
      "epoch": 2.5565217391304347,
      "grad_norm": 0.4085620641708374,
      "learning_rate": 3.0459284542809054e-06,
      "loss": 0.0236,
      "step": 1470
    },
    {
      "epoch": 2.573913043478261,
      "grad_norm": 0.39933452010154724,
      "learning_rate": 2.8188427628551923e-06,
      "loss": 0.0242,
      "step": 1480
    },
    {
      "epoch": 2.591304347826087,
      "grad_norm": 0.3049337863922119,
      "learning_rate": 2.6000472462390845e-06,
      "loss": 0.0246,
      "step": 1490
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": 0.35082072019577026,
      "learning_rate": 2.3896236789342914e-06,
      "loss": 0.0257,
      "step": 1500
    },
    {
      "epoch": 2.626086956521739,
      "grad_norm": 0.4378027617931366,
      "learning_rate": 2.187650706438793e-06,
      "loss": 0.024,
      "step": 1510
    },
    {
      "epoch": 2.643478260869565,
      "grad_norm": 0.37490570545196533,
      "learning_rate": 1.9942038158532407e-06,
      "loss": 0.0212,
      "step": 1520
    },
    {
      "epoch": 2.660869565217391,
      "grad_norm": 0.2984018921852112,
      "learning_rate": 1.8093553076677482e-06,
      "loss": 0.0254,
      "step": 1530
    },
    {
      "epoch": 2.6782608695652175,
      "grad_norm": 0.27168935537338257,
      "learning_rate": 1.633174268739665e-06,
      "loss": 0.0244,
      "step": 1540
    },
    {
      "epoch": 2.6956521739130435,
      "grad_norm": 0.4596897065639496,
      "learning_rate": 1.4657265464725067e-06,
      "loss": 0.0253,
      "step": 1550
    },
    {
      "epoch": 2.7130434782608694,
      "grad_norm": 0.3260693848133087,
      "learning_rate": 1.307074724205551e-06,
      "loss": 0.0236,
      "step": 1560
    },
    {
      "epoch": 2.730434782608696,
      "grad_norm": 0.3233860433101654,
      "learning_rate": 1.1572780978234276e-06,
      "loss": 0.0241,
      "step": 1570
    },
    {
      "epoch": 2.747826086956522,
      "grad_norm": 0.33511143922805786,
      "learning_rate": 1.0163926535943586e-06,
      "loss": 0.0258,
      "step": 1580
    },
    {
      "epoch": 2.765217391304348,
      "grad_norm": 0.22562532126903534,
      "learning_rate": 8.844710472453832e-07,
      "loss": 0.022,
      "step": 1590
    },
    {
      "epoch": 2.782608695652174,
      "grad_norm": 0.448196679353714,
      "learning_rate": 7.615625842823465e-07,
      "loss": 0.0227,
      "step": 1600
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.48147204518318176,
      "learning_rate": 6.477132015620363e-07,
      "loss": 0.0225,
      "step": 1610
    },
    {
      "epoch": 2.8173913043478263,
      "grad_norm": 0.49236029386520386,
      "learning_rate": 5.4296545012337e-07,
      "loss": 0.0249,
      "step": 1620
    },
    {
      "epoch": 2.8347826086956522,
      "grad_norm": 0.36042723059654236,
      "learning_rate": 4.47358479283988e-07,
      "loss": 0.023,
      "step": 1630
    },
    {
      "epoch": 2.8521739130434782,
      "grad_norm": 0.47839057445526123,
      "learning_rate": 3.6092802200826113e-07,
      "loss": 0.0251,
      "step": 1640
    },
    {
      "epoch": 2.869565217391304,
      "grad_norm": 0.36253830790519714,
      "learning_rate": 2.8370638155215123e-07,
      "loss": 0.0236,
      "step": 1650
    },
    {
      "epoch": 2.8869565217391306,
      "grad_norm": 0.32201001048088074,
      "learning_rate": 2.157224193899049e-07,
      "loss": 0.0253,
      "step": 1660
    },
    {
      "epoch": 2.9043478260869566,
      "grad_norm": 0.42069771885871887,
      "learning_rate": 1.57001544427135e-07,
      "loss": 0.0244,
      "step": 1670
    },
    {
      "epoch": 2.9217391304347826,
      "grad_norm": 0.4026537537574768,
      "learning_rate": 1.0756570350427542e-07,
      "loss": 0.0263,
      "step": 1680
    },
    {
      "epoch": 2.9391304347826086,
      "grad_norm": 0.31442737579345703,
      "learning_rate": 6.74333731939647e-08,
      "loss": 0.0241,
      "step": 1690
    },
    {
      "epoch": 2.9565217391304346,
      "grad_norm": 0.3401062488555908,
      "learning_rate": 3.66195528954838e-08,
      "loss": 0.0275,
      "step": 1700
    },
    {
      "epoch": 2.973913043478261,
      "grad_norm": 0.3530162572860718,
      "learning_rate": 1.5135759228732115e-08,
      "loss": 0.0211,
      "step": 1710
    },
    {
      "epoch": 2.991304347826087,
      "grad_norm": 0.40731751918792725,
      "learning_rate": 2.9900217299150267e-09,
      "loss": 0.024,
      "step": 1720
    },
    {
      "epoch": 3.0,
      "step": 1725,
      "total_flos": 1.2700437502073242e+17,
      "train_loss": 0.1276626563763273,
      "train_runtime": 10018.243,
      "train_samples_per_second": 1.377,
      "train_steps_per_second": 0.172
    }
  ],
  "logging_steps": 10,
  "max_steps": 1725,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2700437502073242e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
