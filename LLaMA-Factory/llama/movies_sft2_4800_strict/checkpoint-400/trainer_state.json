{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.6956521739130435,
  "eval_steps": 200.0,
  "global_step": 400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.017391304347826087,
      "grad_norm": 2.3734519481658936,
      "learning_rate": 4.000000000000001e-06,
      "loss": 2.1268,
      "step": 10
    },
    {
      "epoch": 0.034782608695652174,
      "grad_norm": 3.0957276821136475,
      "learning_rate": 8.500000000000002e-06,
      "loss": 2.1612,
      "step": 20
    },
    {
      "epoch": 0.05217391304347826,
      "grad_norm": 2.354733467102051,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 1.8793,
      "step": 30
    },
    {
      "epoch": 0.06956521739130435,
      "grad_norm": 2.864764451980591,
      "learning_rate": 1.85e-05,
      "loss": 1.7846,
      "step": 40
    },
    {
      "epoch": 0.08695652173913043,
      "grad_norm": 2.2347185611724854,
      "learning_rate": 2.35e-05,
      "loss": 1.4548,
      "step": 50
    },
    {
      "epoch": 0.10434782608695652,
      "grad_norm": 2.121521472930908,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 1.098,
      "step": 60
    },
    {
      "epoch": 0.12173913043478261,
      "grad_norm": 1.8027629852294922,
      "learning_rate": 3.35e-05,
      "loss": 0.8733,
      "step": 70
    },
    {
      "epoch": 0.1391304347826087,
      "grad_norm": 1.8203221559524536,
      "learning_rate": 3.85e-05,
      "loss": 0.8241,
      "step": 80
    },
    {
      "epoch": 0.1565217391304348,
      "grad_norm": 2.2270913124084473,
      "learning_rate": 4.35e-05,
      "loss": 0.6496,
      "step": 90
    },
    {
      "epoch": 0.17391304347826086,
      "grad_norm": 1.8486484289169312,
      "learning_rate": 4.85e-05,
      "loss": 0.5406,
      "step": 100
    },
    {
      "epoch": 0.19130434782608696,
      "grad_norm": 1.6372880935668945,
      "learning_rate": 4.999771075391766e-05,
      "loss": 0.4885,
      "step": 110
    },
    {
      "epoch": 0.20869565217391303,
      "grad_norm": 1.949363112449646,
      "learning_rate": 4.998649912931086e-05,
      "loss": 0.3529,
      "step": 120
    },
    {
      "epoch": 0.22608695652173913,
      "grad_norm": 1.1588584184646606,
      "learning_rate": 4.996594883749894e-05,
      "loss": 0.3898,
      "step": 130
    },
    {
      "epoch": 0.24347826086956523,
      "grad_norm": 1.5193570852279663,
      "learning_rate": 4.993606755912317e-05,
      "loss": 0.3852,
      "step": 140
    },
    {
      "epoch": 0.2608695652173913,
      "grad_norm": 1.2164146900177002,
      "learning_rate": 4.989686646226728e-05,
      "loss": 0.2627,
      "step": 150
    },
    {
      "epoch": 0.2782608695652174,
      "grad_norm": 0.8023686408996582,
      "learning_rate": 4.984836019828342e-05,
      "loss": 0.2309,
      "step": 160
    },
    {
      "epoch": 0.2956521739130435,
      "grad_norm": 0.9954809546470642,
      "learning_rate": 4.9790566896316215e-05,
      "loss": 0.2266,
      "step": 170
    },
    {
      "epoch": 0.3130434782608696,
      "grad_norm": 1.0201793909072876,
      "learning_rate": 4.972350815652707e-05,
      "loss": 0.1964,
      "step": 180
    },
    {
      "epoch": 0.33043478260869563,
      "grad_norm": 1.0645273923873901,
      "learning_rate": 4.964720904202108e-05,
      "loss": 0.1941,
      "step": 190
    },
    {
      "epoch": 0.34782608695652173,
      "grad_norm": 2.226503849029541,
      "learning_rate": 4.95616980694798e-05,
      "loss": 0.2052,
      "step": 200
    },
    {
      "epoch": 0.3652173913043478,
      "grad_norm": 1.1100988388061523,
      "learning_rate": 4.946700719850312e-05,
      "loss": 0.1496,
      "step": 210
    },
    {
      "epoch": 0.3826086956521739,
      "grad_norm": 1.822218894958496,
      "learning_rate": 4.9363171819664434e-05,
      "loss": 0.1479,
      "step": 220
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.135585904121399,
      "learning_rate": 4.9250230741283466e-05,
      "loss": 0.1434,
      "step": 230
    },
    {
      "epoch": 0.41739130434782606,
      "grad_norm": 2.7756640911102295,
      "learning_rate": 4.9128226174921736e-05,
      "loss": 0.1343,
      "step": 240
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 0.8688363432884216,
      "learning_rate": 4.899720371960601e-05,
      "loss": 0.148,
      "step": 250
    },
    {
      "epoch": 0.45217391304347826,
      "grad_norm": 1.084541916847229,
      "learning_rate": 4.8857212344785754e-05,
      "loss": 0.1373,
      "step": 260
    },
    {
      "epoch": 0.46956521739130436,
      "grad_norm": 0.7882939577102661,
      "learning_rate": 4.870830437203088e-05,
      "loss": 0.1089,
      "step": 270
    },
    {
      "epoch": 0.48695652173913045,
      "grad_norm": 0.9703043103218079,
      "learning_rate": 4.855053545547664e-05,
      "loss": 0.1065,
      "step": 280
    },
    {
      "epoch": 0.5043478260869565,
      "grad_norm": 0.9051695466041565,
      "learning_rate": 4.8383964561022946e-05,
      "loss": 0.0936,
      "step": 290
    },
    {
      "epoch": 0.5217391304347826,
      "grad_norm": 0.6563939452171326,
      "learning_rate": 4.820865394429597e-05,
      "loss": 0.0783,
      "step": 300
    },
    {
      "epoch": 0.5391304347826087,
      "grad_norm": 2.0840580463409424,
      "learning_rate": 4.802466912738022e-05,
      "loss": 0.0794,
      "step": 310
    },
    {
      "epoch": 0.5565217391304348,
      "grad_norm": 1.070469856262207,
      "learning_rate": 4.783207887432971e-05,
      "loss": 0.0779,
      "step": 320
    },
    {
      "epoch": 0.5739130434782609,
      "grad_norm": 0.9281961917877197,
      "learning_rate": 4.7630955165467536e-05,
      "loss": 0.0727,
      "step": 330
    },
    {
      "epoch": 0.591304347826087,
      "grad_norm": 0.7443646788597107,
      "learning_rate": 4.742137317048331e-05,
      "loss": 0.0821,
      "step": 340
    },
    {
      "epoch": 0.6086956521739131,
      "grad_norm": 0.6137827634811401,
      "learning_rate": 4.720341122033862e-05,
      "loss": 0.0665,
      "step": 350
    },
    {
      "epoch": 0.6260869565217392,
      "grad_norm": 0.5794081687927246,
      "learning_rate": 4.697715077799091e-05,
      "loss": 0.066,
      "step": 360
    },
    {
      "epoch": 0.6434782608695652,
      "grad_norm": 0.9558050632476807,
      "learning_rate": 4.6742676407946886e-05,
      "loss": 0.0555,
      "step": 370
    },
    {
      "epoch": 0.6608695652173913,
      "grad_norm": 0.67464280128479,
      "learning_rate": 4.6500075744656605e-05,
      "loss": 0.0514,
      "step": 380
    },
    {
      "epoch": 0.6782608695652174,
      "grad_norm": 0.5215206742286682,
      "learning_rate": 4.624943945976023e-05,
      "loss": 0.0472,
      "step": 390
    },
    {
      "epoch": 0.6956521739130435,
      "grad_norm": 0.7594699859619141,
      "learning_rate": 4.599086122819966e-05,
      "loss": 0.0621,
      "step": 400
    }
  ],
  "logging_steps": 10,
  "max_steps": 1725,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.9267548011823104e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
